{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Belief Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Base Improved\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, roc_auc_score\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# # Load dataset\n",
    "# df = pd.read_csv(\"df.csv\")  # Replace with actual file path\n",
    "\n",
    "# # Encoding categorical labels\n",
    "# label_encoder = LabelEncoder()\n",
    "# df[\"Class\"] = label_encoder.fit_transform(df[\"Class\"])\n",
    "# df[\"theft\"] = label_encoder.fit_transform(df[\"theft\"])\n",
    "\n",
    "# # Define features and target variable\n",
    "# feature_cols = [\n",
    "#     \"Electricity:Facility [kW](Hourly)\", \"Fans:Electricity [kW](Hourly)\", \"Cooling:Electricity [kW](Hourly)\",\n",
    "#     \"Heating:Electricity [kW](Hourly)\", \"InteriorLights:Electricity [kW](Hourly)\", \"InteriorEquipment:Electricity [kW](Hourly)\",\n",
    "#     \"Gas:Facility [kW](Hourly)\", \"Heating:Gas [kW](Hourly)\", \"InteriorEquipment:Gas [kW](Hourly)\",\n",
    "#     \"Water Heater:WaterSystems:Gas [kW](Hourly)\"\n",
    "# ]\n",
    "# X = df[feature_cols]\n",
    "# y = df[\"theft\"]\n",
    "\n",
    "# # Split data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Function to evaluate models\n",
    "# def evaluate_model(model, name):\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     auc_score = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr') if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "#     results = {\n",
    "#         \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "#         \"F1-score\": f1_score(y_test, y_pred, average='weighted'),\n",
    "#         \"Kappa\": cohen_kappa_score(y_test, y_pred),\n",
    "#         \"AUC\": auc_score\n",
    "#     }\n",
    "#     print(f\"Results for {name}:\\n\", results, \"\\n\")\n",
    "#     return results\n",
    "\n",
    "# # Define models with pipelines\n",
    "# pipelines = {\n",
    "#     \"KNN\": Pipeline([\n",
    "#         ('scaler', MinMaxScaler()),\n",
    "#         ('classifier', KNeighborsClassifier())\n",
    "#     ]),\n",
    "#     \"DecisionTree\": Pipeline([\n",
    "#         ('scaler', MinMaxScaler()),\n",
    "#         ('classifier', DecisionTreeClassifier())\n",
    "#     ]),\n",
    "#     \"RandomForest\": Pipeline([\n",
    "#         ('scaler', MinMaxScaler()),\n",
    "#         ('classifier', RandomForestClassifier())\n",
    "#     ]),\n",
    "#     \"Bagging\": Pipeline([\n",
    "#         ('scaler', MinMaxScaler()),\n",
    "#         ('classifier', BaggingClassifier(KNeighborsClassifier()))\n",
    "#     ]),\n",
    "#     \"ANN\": Pipeline([\n",
    "#         ('scaler', MinMaxScaler()),\n",
    "#         ('classifier', MLPClassifier(max_iter=500))\n",
    "#     ])\n",
    "# }\n",
    "\n",
    "# # Define hyperparameter grids for GridSearchCV\n",
    "# param_grids = {\n",
    "#     \"KNN\": {\"classifier__n_neighbors\": [5, 10, 15]},\n",
    "#     \"DecisionTree\": {\"classifier__max_depth\": [5, 10, None]},\n",
    "#     \"RandomForest\": {\"classifier__n_estimators\": [50, 100, 200]},\n",
    "#     \"Bagging\": {\"classifier__n_estimators\": [5, 10, 20]},\n",
    "#     \"ANN\": {\n",
    "#     \"classifier__hidden_layer_sizes\": [(20, 20), (50, 50), (100, 50)],  \n",
    "#     \"classifier__max_iter\": [300, 500, 1000],  \n",
    "#     \"classifier__solver\": [\"adam\", \"lbfgs\"],  \n",
    "#     \"classifier__alpha\": [0.0001, 0.001],  \n",
    "#     \"classifier__early_stopping\": [True]  \n",
    "#     }\n",
    "\n",
    "# }\n",
    "\n",
    "# # Perform GridSearchCV to optimize models\n",
    "# best_models = {}\n",
    "# for name, pipeline in pipelines.items():\n",
    "#     print(f\"Optimizing {name}...\")\n",
    "#     grid_search = GridSearchCV(pipeline, param_grid=param_grids[name], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "#     grid_search.fit(X_train, y_train)\n",
    "#     best_models[name] = grid_search.best_estimator_\n",
    "#     print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "\n",
    "# # Evaluate optimized models\n",
    "# final_results = {name: evaluate_model(model, name) for name, model in best_models.items()}\n",
    "\n",
    "# # Print final comparison\n",
    "# print(\"Final Model Comparison:\\n\", final_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler, LabelEncoder\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"df.csv\")  # Replace with actual dataset path\n",
    "\n",
    "# Encode categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"Class\"] = label_encoder.fit_transform(df[\"Class\"])\n",
    "df[\"theft\"] = label_encoder.fit_transform(df[\"theft\"])\n",
    "\n",
    "# Feature selection\n",
    "feature_cols = [\n",
    "    \"Electricity:Facility [kW](Hourly)\", \"Fans:Electricity [kW](Hourly)\", \"Cooling:Electricity [kW](Hourly)\",\n",
    "    \"Heating:Electricity [kW](Hourly)\", \"InteriorLights:Electricity [kW](Hourly)\", \"InteriorEquipment:Electricity [kW](Hourly)\",\n",
    "    \"Gas:Facility [kW](Hourly)\", \"Heating:Gas [kW](Hourly)\", \"InteriorEquipment:Gas [kW](Hourly)\",\n",
    "    \"Water Heater:WaterSystems:Gas [kW](Hourly)\"\n",
    "]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[\"theft\"]\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply SMOTE to balance data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "X_train_resampled = scaler.fit_transform(X_train_resampled)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 1Ô∏è‚É£ **LightGBM Model**\n",
    "lgb_model = lgb.LGBMClassifier(n_estimators=200, learning_rate=0.05, max_depth=10)\n",
    "lgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "y_pred_proba_lgb = lgb_model.predict_proba(X_test)\n",
    "\n",
    "# Evaluate LightGBM\n",
    "results_lgb = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_lgb),\n",
    "    \"F1-score\": f1_score(y_test, y_pred_lgb, average='weighted'),\n",
    "    \"Kappa\": cohen_kappa_score(y_test, y_pred_lgb),\n",
    "    \"AUC\": roc_auc_score(y_test, y_pred_proba_lgb, multi_class='ovr')\n",
    "}\n",
    "print(\"\\nüîç **LightGBM Results:**\")\n",
    "print(results_lgb)\n",
    "print(\"\\nüìä Confusion Matrix (LightGBM):\\n\", confusion_matrix(y_test, y_pred_lgb))\n",
    "\n",
    "# 2Ô∏è‚É£ **Stacking Model**\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=10)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, max_depth=10)),\n",
    "    ('xgb', XGBClassifier(n_estimators=200, learning_rate=0.1))\n",
    "]\n",
    "\n",
    "# Define meta-model\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
    "\n",
    "# Train stacking model\n",
    "stacking_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predictions\n",
    "y_pred_stack = stacking_model.predict(X_test)\n",
    "y_pred_proba_stack = stacking_model.predict_proba(X_test)\n",
    "\n",
    "# Evaluate Stacking Model\n",
    "results_stack = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_stack),\n",
    "    \"F1-score\": f1_score(y_test, y_pred_stack, average='weighted'),\n",
    "    \"Kappa\": cohen_kappa_score(y_test, y_pred_stack),\n",
    "    \"AUC\": roc_auc_score(y_test, y_pred_proba_stack, multi_class='ovr')\n",
    "}\n",
    "print(\"\\nüîç **Stacking Model Results:**\")\n",
    "print(results_stack)\n",
    "print(\"\\nüìä Confusion Matrix (Stacking):\\n\", confusion_matrix(y_test, y_pred_stack))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEE205",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
